{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import expit\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "### Forward mode & dual numbers\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Dual_number\n",
    "- https://blog.demofox.org/2014/12/30/dual-numbers-automatic-differentiation/\n",
    "- https://blog.demofox.org/2017/02/20/multivariable-dual-numbers-automatic-differentiation/\n",
    "- https://marksaroufim.medium.com/automatic-differentiation-step-by-step-24240f97a6e6\n",
    "\n",
    "### Backward mode & backpropagation\n",
    "\n",
    "- https://www.jmlr.org/papers/volume18/17-468/17-468.pdf\n",
    "- https://sidsite.com/posts/autodiff/\n",
    "- https://github.com/karpathy/micrograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, value):\n",
    "        if isinstance(value, (int, float)):\n",
    "            value = [value]\n",
    "\n",
    "        self.value = np.array(value)\n",
    "        \n",
    "        self.grad = None\n",
    "        self.children = []\n",
    "        \n",
    "    @property\n",
    "    def leaf_node(self):\n",
    "        return not bool(self.children)\n",
    "        \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.value.shape\n",
    "    \n",
    "    @property\n",
    "    def safe_grad(self):\n",
    "        return self.zeros(self.shape) if self.grad is None else self.grad\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_input(value):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return Tensor([value])\n",
    "        elif isinstance(value, (list, np.ndarray)):\n",
    "            return Tensor(value)\n",
    "        return value\n",
    "    \n",
    "    # magick, тут я честно наоубом захуярил\n",
    "    @staticmethod\n",
    "    def unbroadcast(out, in_shape):\n",
    "        sum_axis = None\n",
    "        # Need to sum all axis with 1 = in_shape[i] < out.shape[i]\n",
    "        if in_shape != (1,):\n",
    "            sum_axis = tuple([i for i in range(len(in_shape)) if in_shape[i] == 1 and out.shape[i] > 1])\n",
    "\n",
    "        return Tensor(out.value.sum(axis=sum_axis).reshape(in_shape))\n",
    "    \n",
    "    @staticmethod\n",
    "    def ones(shape):\n",
    "        return Tensor(np.ones(shape))\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros(shape):\n",
    "        return Tensor(np.zeros(shape))\n",
    "        \n",
    "    @staticmethod\n",
    "    def uniform(shape):\n",
    "        return Tensor(np.random.uniform(size=shape))\n",
    "        \n",
    "    @staticmethod\n",
    "    def topsort(root):\n",
    "        sort, visited = deque(), set()\n",
    "        \n",
    "        def dfs(node):\n",
    "            for child in node.children:\n",
    "                if child not in visited:\n",
    "                    visited.add(child)\n",
    "                    dfs(child)\n",
    "            sort.appendleft(node)\n",
    "        \n",
    "        dfs(root)\n",
    "        return sort\n",
    "    \n",
    "    def backward(self):\n",
    "        topsort = self.topsort(self)\n",
    "        self.grad = self.ones(self.shape)\n",
    "        \n",
    "        for root in topsort:\n",
    "            if not root.leaf_node:\n",
    "                out_grad = root._backward(root.grad.value)\n",
    "                \n",
    "                for i, child in enumerate(root.children):  \n",
    "                    child.grad = child.safe_grad + out_grad[i]\n",
    "                    child.grad = self.unbroadcast(child.grad, child.shape)\n",
    "                    \n",
    "    def reshape(self, *shapes):\n",
    "        return Tensor(self.value.reshape(*shapes))\n",
    "    \n",
    "    def sum(self):\n",
    "        node = Tensor(self.value.sum(axis=None))\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din]\n",
    "        \n",
    "        node._backward = _backward\n",
    "        node.children = [self]\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def norm(self):\n",
    "        return np.linalg.norm(self.value)\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        exp = expit(self.value)\n",
    "        \n",
    "        node = Tensor(exp)\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din * exp * (1 - exp)]\n",
    "        \n",
    "        node._backward = _backward\n",
    "        node.children = [self]\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def relu(self):\n",
    "        node = Tensor(np.maximum(0, self.value))\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din * (self.value >= 0)]\n",
    "        \n",
    "        node._backward = _backward\n",
    "        node.children = [self]\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def __matmul__(self, other):\n",
    "        node = Tensor(self.value @ other.value)\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din @ other.value.T, self.value.T @ din]\n",
    "        \n",
    "        node._backward = _backward\n",
    "        node.children = [self, other]\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def __rmatmul__(self, other):\n",
    "        pass\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        other = self.check_input(other)\n",
    "        \n",
    "        node = Tensor(self.value + other.value)\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din, din]\n",
    "\n",
    "        node._backward = _backward\n",
    "        node.children = [self, other]\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        other = self.check_input(other)\n",
    "        self.value = self.value + other.value\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __isub__(self, other):\n",
    "        other = self.check_input(other)\n",
    "        self.value = self.value - other.value\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = self.check_input(other)\n",
    "        \n",
    "        node = Tensor(self.value * other.value)\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din * other.value, din * self.value]\n",
    "\n",
    "        node._backward = _backward\n",
    "        node.children = [self, other]\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float))\n",
    "        \n",
    "        node = Tensor(self.value ** other)\n",
    "        \n",
    "        def _backward(din):\n",
    "            return [din * (other * self.value ** (other - 1))]\n",
    "        \n",
    "        node._backward = _backward\n",
    "        node.children = [self]\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        array_repr = \",\\n\".join([7*\" \" + str(line) if i > 0 else str(line) for i, line in enumerate(self.value)])\n",
    "                \n",
    "        return f\"Tensor({array_repr})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.random.uniform(size=(2, 3))\n",
    "y_ = np.random.uniform(size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x_, requires_grad=True)\n",
    "y = torch.tensor(y_, requires_grad=True)\n",
    "z = torch.sum((x - y)**2)\n",
    "\n",
    "z.backward(torch.ones_like(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4898,  0.7357,  0.0955],\n",
       "        [ 1.3376, -0.1113,  0.1987]], dtype=torch.float64)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = Tensor(x_)\n",
    "my = Tensor(y_)\n",
    "mz = ((mx - my)**2).sum()\n",
    "\n",
    "mz.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([0.48984973 0.73570217 0.09549759],\n",
       "       [ 1.33759629 -0.11125404  0.19871018])"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check grads with torch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        self.W = Tensor.uniform((in_shape, out_shape))\n",
    "        self.b = Tensor.uniform((1, out_shape))\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return (X @ self.W) + self.b\n",
    "\n",
    "\n",
    "class SimpleRegNet:\n",
    "    def __init__(self, in_shape):\n",
    "        self.l1 = Linear(in_shape, 32) \n",
    "        self.l2 = Linear(32, 32)\n",
    "        self.l3 = Linear(32, 1)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return [self.l1.W, self.l1.b, self.l2.W, self.l2.b, self.l3.W, self.l3.b]\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.grad = None\n",
    "            \n",
    "    def __call__(self, X):\n",
    "        x = self.l1(X)\n",
    "        x = self.l2(x)\n",
    "        \n",
    "        return self.l3(x)\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    return ((y_pred - y_true)**2).sum() * (1 / y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_, y_ = make_regression(100, 1, bias=15.0, noise=20)\n",
    "X, y = Tensor(X_), Tensor(y_).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28056.231660523223\n",
      "23317.460627531527\n",
      "19210.740269910475\n",
      "15675.55940664438\n",
      "12655.153428664888\n",
      "10096.378293791548\n",
      "7949.586483538012\n",
      "6168.504919036088\n",
      "4710.114806217724\n",
      "3534.533317025505\n",
      "2604.896865521048\n",
      "1887.2453822940013\n",
      "1350.4060872675568\n",
      "965.8727641155995\n",
      "707.6687641584429\n",
      "552.1533953424004\n",
      "459.8961726404722\n",
      "406.2587842235396\n",
      "383.8716818432483\n",
      "378.85803893895167\n",
      "383.97787381974183\n",
      "378.60385714378623\n",
      "383.6864430526381\n",
      "378.41491533421424\n",
      "383.46843437321564\n",
      "378.27378557657175\n",
      "383.30436486915977\n",
      "378.16747069627877\n",
      "383.17968214714864\n",
      "378.0863747538793\n",
      "383.0836133801105\n",
      "378.0234706041244\n",
      "383.00824419202104\n",
      "377.97364640104877\n",
      "382.94779774364974\n",
      "377.93320384783226\n",
      "382.89808064225565\n",
      "377.8994794109223\n",
      "382.85606327946465\n",
      "377.8705620629433\n",
      "382.81956575408105\n",
      "377.84508508232705\n",
      "382.78702509796915\n",
      "377.8220737093269\n",
      "382.75732414109643\n",
      "377.80083439026066\n",
      "382.72966653285636\n",
      "377.7808746788641\n",
      "382.7034859826199\n",
      "377.76184555990477\n"
     ]
    }
   ],
   "source": [
    "net = SimpleRegNet(X.shape[1])\n",
    "lr = 0.1\n",
    "\n",
    "for i in range(50):\n",
    "    net.zero_grad()\n",
    "    \n",
    "    loss = mse(net(X), y)\n",
    "    loss.backward()\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        param -= lr * param.grad * (1 / param.grad.norm())\n",
    "\n",
    "    print(loss.value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x139280150>"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_, y_)\n",
    "plt.scatter(X_, net(X).value, c=\"red\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "X_, y_ = load_boston()[\"data\"], load_boston()[\"target\"]\n",
    "X, y = Tensor(X_), Tensor(y_).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ff0f1a8ca4cd28ca7e0b66798463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "54.54732220984849\n"
     ]
    }
   ],
   "source": [
    "net = SimpleRegNet(X.shape[1])\n",
    "lr = 0.1\n",
    "\n",
    "for i in tqdm(range(10_000)):\n",
    "    net.zero_grad()\n",
    "    \n",
    "    loss = mse(net(X), y)\n",
    "    loss.backward()\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        lr = lr / (1 + 2e-6 * i)\n",
    "        \n",
    "        param -= lr * param.grad * (1 / param.grad.norm())\n",
    "\n",
    "print(loss.value[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
