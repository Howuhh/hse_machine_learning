{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PjQglGj4q54"
   },
   "source": [
    "# Случайные леса\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[ML][MS][HW09] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n",
    "\n",
    "В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LH5PiGz04q5-"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bQUJHTjS4q5-"
   },
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    proba = np.bincount(x) / x.shape[0]\n",
    "#     _, counts = np.unique(x, return_counts=True)\n",
    "#     proba = counts / len(x)\n",
    "    return np.sum(proba * (1 - proba))\n",
    "    \n",
    "def entropy(x):\n",
    "    proba = np.bincount(x) / x.shape[0]\n",
    "#     _, counts = np.unique(x, return_counts=True)\n",
    "#     proba = counts / len(x)\n",
    "    return -np.sum(proba * np.log2(proba + 1e-16))\n",
    "\n",
    "def gain(left_y, right_y, criterion):\n",
    "    N = len(left_y) + len(right_y)\n",
    "    \n",
    "    return (criterion(left_y) * len(left_y) + criterion(right_y) * len(right_y)) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfxycK0Q4q5_"
   },
   "source": [
    "### Задание 1 (2 балла)\n",
    "Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n",
    "\n",
    "Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n",
    "\n",
    "#### Методы\n",
    "`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n",
    "\n",
    "`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n",
    "\n",
    "`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n",
    "\n",
    "`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n",
    "\n",
    "`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8smLW2V_4q5_"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, split_dim, split_value, left=None, right=None):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_value = split_value\n",
    "        self.left, self.right = left, right\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, labels, n_classes):\n",
    "        self.prediction = self._predict(labels, n_classes)\n",
    "        \n",
    "    def _predict(self, x, n_classes):\n",
    "        prediction = np.zeros(n_classes)\n",
    "    \n",
    "        labels, counts = np.unique(x, return_counts=True)\n",
    "        prediction[labels] = counts / x.shape[0]\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, X, y, n_classes, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\"):\n",
    "        criterions = {'gini': gini, 'entropy': entropy}\n",
    "        \n",
    "        self.criterion = criterions[criterion]\n",
    "        self.max_depth = max_depth if max_depth is not None else np.inf\n",
    "        self.max_features = np.sqrt(X.shape[1]).astype(np.int) if max_features == \"auto\" else max_features\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "        self.train_idx, self.oob_idx = self._bootstrap_train(X.shape[0])\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.root = self._fit(X[self.train_idx], y[self.train_idx])\n",
    "\n",
    "\n",
    "    def _bootstrap_train(self, N):\n",
    "        sample_idx = np.random.choice(N, N, replace=True)\n",
    "        \n",
    "        return sample_idx, np.setdiff1d(np.arange(N), sample_idx)\n",
    "    \n",
    "    def _fit(self, X, y, depth=1):\n",
    "        if depth >= self.max_depth:\n",
    "            return Leaf(y, self.n_classes)\n",
    "        \n",
    "        split_dim, split_value = None, None\n",
    "        \n",
    "        # find best split\n",
    "        best_gain = np.inf\n",
    "        for feature in np.random.choice(X.shape[1], self.max_features, replace=False):\n",
    "            split_mask = X[:, feature] < 0.5 # only bool features\n",
    "\n",
    "            y_left, y_right = y[split_mask], y[~split_mask]\n",
    "            gain_value = gain(y_left, y_right, self.criterion)\n",
    "\n",
    "            not_leaf = y_left.shape[0] >= self.min_samples_leaf and y_right.shape[0] >= self.min_samples_leaf\n",
    "\n",
    "            if gain_value < best_gain and not_leaf:\n",
    "                split_dim, split_value, best_gain = feature, 0.5, gain_value\n",
    "\n",
    "        if split_dim is None:\n",
    "            return Leaf(y, self.n_classes)\n",
    "    \n",
    "        split_mask = X[:, split_dim] < split_value\n",
    "        \n",
    "        root = Node(split_dim, split_value)\n",
    "        root.left = self._fit(X[split_mask], y[split_mask], depth + 1)\n",
    "        root.right = self._fit(X[~split_mask], y[~split_mask], depth + 1)\n",
    "        \n",
    "        return root\n",
    "    \n",
    "    def _predict_row(self, x, root):\n",
    "        if isinstance(root, Leaf):\n",
    "            return root.prediction\n",
    "        \n",
    "        if x[root.split_dim] < root.split_value:\n",
    "            return self._predict_row(x, root.left)\n",
    "        else:\n",
    "            return self._predict_row(x, root.right)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        probs = np.zeros((X.shape[0], self.n_classes))\n",
    "\n",
    "        for i, row in enumerate(X):\n",
    "            probs[i] = self._predict_row(row, self.root)\n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oijgwLt4q6A"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n",
    "\n",
    "#### Параметры конструктора\n",
    "`n_estimators` - количество используемых для предсказания деревьев.\n",
    "\n",
    "Остальное - параметры деревьев.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
    "\n",
    "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "APIy88YW4q6A"
   },
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n",
    "        self.estimators = None\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def fit(self, X, y):        \n",
    "        n_classes = np.unique(y).shape[0]\n",
    "        \n",
    "        self.estimators = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTree(X, y, n_classes, self.criterion, self.max_depth, \n",
    "                                self.min_samples_leaf, self.max_features)\n",
    "            self.estimators.append(tree)\n",
    "                           \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.estimators is None:\n",
    "            raise AttributeError(\"Fit model first!\")\n",
    "            \n",
    "        prediction = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, estimator in enumerate(self.estimators):\n",
    "            prediction[i] = estimator.predict(X)\n",
    "        \n",
    "        return scipy.stats.mode(prediction, axis=0)[0].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i80pffMn4q6A"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n",
    "\n",
    "Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rEmVG1Fl4q6B"
   },
   "outputs": [],
   "source": [
    "def feature_importance(rfc, X, y):\n",
    "    importance = np.zeros((rfc.n_estimators, X.shape[1]))\n",
    "    \n",
    "    err_oob = [(1 - np.mean(tree.predict(X[tree.oob_idx]) == y[tree.oob_idx])) for tree in rfc.estimators]\n",
    "    \n",
    "    for feature in range(X.shape[1]):\n",
    "        X_perm = X.copy()\n",
    "        X_perm[:, feature] = np.random.permutation(X_perm[:, feature])\n",
    "\n",
    "        for i, tree in enumerate(rfc.estimators):\n",
    "            X_oob, y_oob = X_perm[tree.oob_idx], y[tree.oob_idx]\n",
    "            \n",
    "            err_oob_i = 1 - np.mean(tree.predict(X_oob) == y_oob)\n",
    "            importance[i, feature] = err_oob_i - err_oob[i]        \n",
    "    \n",
    "    return importance.mean(axis=0)\n",
    "\n",
    "def most_important_features(importance, names, k=20):\n",
    "    # Выводит названия k самых важных признаков\n",
    "    idicies = np.argsort(importance)[::-1][:k]\n",
    "    return np.array(names)[idicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JooN_YKm4q6B"
   },
   "source": [
    "Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8gqYMp994q6B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Importance: [-3.41187787e-04  7.26933540e-05  1.45667306e-01  1.42977053e-01\n",
      "  3.20689228e-01 -5.29974508e-05]\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dataset(size):\n",
    "    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n",
    "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n",
    "    y = [i % 3 for i in range(size)]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n",
    "print(\"Importance:\", feature_importance(rfc, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRtGOs164q6C"
   },
   "source": [
    "### Задание 4 (1 балл)\n",
    "Теперь поработаем с реальными данными.\n",
    "\n",
    "Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n",
    "\\\n",
    "Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HruobK-q4q6C"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    dataframe = pandas.read_csv(path, header=0)\n",
    "    dataset = dataframe.values.tolist()\n",
    "    random.shuffle(dataset)\n",
    "    y_age = [row[0] for row in dataset]\n",
    "    y_sex = [row[1] for row in dataset]\n",
    "    X = [row[2:] for row in dataset]\n",
    "    \n",
    "    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K0QXWr3b4q6C"
   },
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "\n",
    "y_age_labels, y_age = np.unique(y_age, return_inverse=True)\n",
    "y_sex_labels, y_sex = np.unique(y_sex, return_inverse=True)\n",
    "\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0y8J97m4q6C"
   },
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MLJykJZH4q6C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7099621689785625\n",
      "CPU times: user 51.8 s, sys: 1.45 s, total: 53.3 s\n",
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=10, criterion=\"entropy\")\n",
    "rfc.fit(X_train, y_age_train)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_age_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features:\n",
      "1. ovsyanochan\n",
      "2. 4ch\n",
      "3. mudakoff\n",
      "4. rhymes\n",
      "5. styd.pozor\n",
      "6. pravdashowtop\n",
      "7. pustota_diary\n",
      "8. pixel_stickers\n",
      "9. rapnewrap\n",
      "10. bot_maxim\n",
      "11. iwantyou\n",
      "12. dayvinchik\n",
      "13. tumblr_vacuum\n",
      "14. dzenpub\n",
      "15. leprum\n",
      "16. xfilm\n",
      "17. ohhluul\n",
      "18. ne1party\n",
      "19. femalemem\n",
      "20. bestad\n",
      "CPU times: user 6min 2s, sys: 3.43 s, total: 6min 5s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc, X_train, y_age_train), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgNpaAKH4q6D"
   },
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X-zne5-R4q6D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8575031525851198\n",
      "CPU times: user 48.5 s, sys: 1.59 s, total: 50.1 s\n",
      "Wall time: 53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=10, criterion=\"entropy\")\n",
    "rfc.fit(X_train, y_sex_train)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_sex_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features:\n",
      "1. leprum\n",
      "2. 21jqofa\n",
      "3. i.kino\n",
      "4. ne.poverish\n",
      "5. memeboizz\n",
      "6. leprazo\n",
      "7. komment.broo\n",
      "8. top_screens\n",
      "9. ru.esquire\n",
      "10. mash\n",
      "11. pho\n",
      "12. rem_shkola\n",
      "13. webestano\n",
      "14. ultrapir\n",
      "15. ftp_memes\n",
      "16. fucking_humor\n",
      "17. vandroukiru\n",
      "18. dzenpub\n",
      "19. morgenshtern666\n",
      "20. vulgaarr\n",
      "CPU times: user 6min 26s, sys: 7.32 s, total: 6min 33s\n",
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc, X_train, y_sex_train), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxeTQylQ4q6D"
   },
   "source": [
    "### CatBoost\n",
    "В качестве аьтернативы попробуем CatBoost. \n",
    "\n",
    "Устаниовить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n",
    "\\\n",
    "Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DOqVkEnd4q6D",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Importance: [6.46582749e-03 1.28538611e-02 2.78343165e+01 2.78247365e+01\n",
      " 4.43118985e+01 9.72883594e-03]\n"
     ]
    }
   ],
   "source": [
    "X, y = synthetic_dataset(1000)\n",
    "\n",
    "model = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(model.predict(X).flatten() == y))\n",
    "print(\"Importance:\", model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcLRsSNG4q6E"
   },
   "source": [
    "### Задание 5 (3 балла)\n",
    "Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hJGrQcO-4q6E"
   },
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
    "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA5f_8eC4q6E"
   },
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "qSeUpxPj4q6E",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7641866330390921\n",
      "Most important features:\n",
      "1. ovsyanochan : 2.9137\n",
      "2. mudakoff : 2.9035\n",
      "3. 4ch : 2.2852\n",
      "4. styd.pozor : 2.2254\n",
      "5. rhymes : 2.0737\n",
      "6. dayvinchik : 1.93\n",
      "7. xfilm : 1.8566\n",
      "8. leprum : 1.7797\n",
      "9. rapnewrap : 1.7214\n",
      "10. fuck_humor : 1.5567\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "model.fit(X_train, y_age_train)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(model.predict(X_test).flatten() == y_age_test))\n",
    "print(\"Most important features:\")\n",
    "for i, (imp, name) in enumerate(sorted(zip(model.feature_importances_, features), reverse=True)[:10]):\n",
    "    print(str(i+1) + \".\", name, \":\", round(imp, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfYSptm74q6E"
   },
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4rKa-f6F4q6E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8738965952080706\n",
      "Most important features:\n",
      "1. 40kg : 4.0741\n",
      "2. mudakoff : 3.1424\n",
      "3. modnailru : 2.3034\n",
      "4. girlmeme : 2.2499\n",
      "5. rapnewrap : 1.7651\n",
      "6. 4ch : 1.6958\n",
      "7. academyofman : 1.6609\n",
      "8. 9o_6o_9o : 1.6199\n",
      "9. femalemem : 1.5404\n",
      "10. i_d_t : 1.5252\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "model.fit(X_train, y_sex_train)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(model.predict(X_test).flatten() == y_sex_test))\n",
    "print(\"Most important features:\")\n",
    "\n",
    "for i, (imp, name) in enumerate(sorted(zip(model.feature_importances_, features), reverse=True)[:10]):\n",
    "    print(str(i+1) + \".\", name, \":\", round(imp, 4))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw09_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
